<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Miryam  de Lhoneux | publications</title>
<meta name="description" content="Miryam de Lhoneux's homepage
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŒ³</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Miryam</span>   de Lhoneux
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                teaching
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description"></p>
  </header>

  <article>
    <p><a href="/publications#publications">publications</a> and <a href="/publications#talks">talks</a></p>

<h1 class="category">Publications</h1>
<p><span id="publications"></span></p>

<div class="publications">
<h4 class="category"> Conference papers and journal articles</h4>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">AmericasNLP ST</abbr>
        
    
</div>

  <div id="bollmann-etal-2021-moses" class="col-sm-9">
    
      <div class="title">Moses and the Character-Based Random Babbling Baseline: CoAStaL at AmericasNLP 2021 Shared Task</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Marcel Bollmann,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rahul Aralikatte,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  HÃ©ctor Murrieta Bello,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daniel Hershcovich,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Anders SÃ¸gaard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas</em>,
      
      
        2021
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/2021.americasnlp-1.28" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We evaluated a range of neural machine translation techniques developed specifically for low-resource scenarios. Unsuccessfully. In the end, we submitted two runs: (i) a standard phrase-based model, and (ii) a random babbling baseline using character trigrams. We found that it was surprisingly hard to beat (i), in spite of this model being, in theory, a bad fit for polysynthetic languages; and more interestingly, that (ii) was better than several of the submitted systems, highlighting how difficult low-resource machine translation for polysynthetic languages is.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{bollmann-etal-2021-moses,
  title = {{M}oses and the Character-Based Random Babbling Baseline: {C}o{AS}ta{L} at {A}mericas{NLP} 2021 Shared Task},
  author = {Bollmann, Marcel and Aralikatte, Rahul and Murrieta Bello, H{\'e}ctor and Hershcovich, Daniel and {de Lhoneux}, Miryam and S{\o}gaard, Anders},
  booktitle = {Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas},
  month = jun,
  year = {2021},
  abbr = {AmericasNLP ST},
  address = {Online},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/2021.americasnlp-1.28},
  doi = {10.18653/v1/2021.americasnlp-1.28},
  pages = {248--254}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">IWPT EUD ST</abbr>
        
    
</div>

  <div id="hershcovich20koepsala" class="col-sm-9">
    
      <div class="title">KÃ¸psala: Transition-Based Graph Parsing via Efficient Training and Effective Encoding</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Daniel Hershcovich,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Artur Kulmizev,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Elham Pejhan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</em>,
      
      
        2020
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/2020.iwpt-1.25" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present KÃ¸psala, the Copenhagen-Uppsala system for the Enhanced Universal Dependencies Shared Task at IWPT 2020. Our system is a pipeline consisting of off-the-shelf models for everything but enhanced graph parsing, and for the latter, a transition-based graph parser adapted from Che et al. (2019). We train a single enhanced parser model per language, using gold sentence splitting and tokenization for training, and rely only on tokenized surface forms and multilingual BERT for encoding. While a bug introduced just before submission resulted in a severe drop in precision, its post-submission fix would bring us to 4th place in the official ranking, according to average ELAS. Our parser demonstrates that a unified pipeline is effective for both Meaning Representation Parsing and Enhanced Universal Dependencies.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{hershcovich20koepsala,
  title = {{K}{\o}psala: Transition-Based Graph Parsing via Efficient Training and Effective Encoding},
  author = {Hershcovich, Daniel and {de Lhoneux}, Miryam and Kulmizev, Artur and Pejhan, Elham and Nivre, Joakim},
  booktitle = {Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies},
  month = jul,
  year = {2020},
  address = {Online},
  abbr = {IWPT EUD ST},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/2020.iwpt-1.25},
  doi = {10.18653/v1/2020.iwpt-1.25},
  pages = {236--244}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">COLING</abbr>
        
    
</div>

  <div id="hershcovich-etal-2020-comparison" class="col-sm-9">
    
      <div class="title">Comparison by Conversion: Reverse-Engineering UCCA from Syntax and Lexical Semantics</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Daniel Hershcovich,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nathan Schneider,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dotan Dvir,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jakob Prange,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Miryam Lhoneux,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Omri Abend
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proceedings of the 28th International Conference on Computational Linguistics</em>,
      
      
        2020
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/2020.coling-main.264" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Transition-based and graph-based dependency parsers have previously been shown to have complementary strengths and weaknesses: transition-based parsers exploit rich structural features but suffer from error propagation, while graph-based parsers benefit from global optimization but have restricted feature scope. In this paper, we show that, even though some details of the picture have changed after the switch to neural networks and continuous representations, the basic trade-off between rich features and global optimization remains essentially the same. Moreover, we show that deep contextualized word embeddings, which allow parsers to pack information about global sentence structure into local feature representations, benefit transition-based parsers more than graph-based parsers, making the two approaches virtually equivalent in terms of both accuracy and error profile. We argue that the reason is that these representations help prevent search errors and thereby allow transition-based parsers to better exploit their inherent strength of making accurate local decisions. We support this explanation by an error analysis of parsing experiments on 13 languages.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{hershcovich-etal-2020-comparison,
  title = {Comparison by Conversion: Reverse-Engineering {UCCA} from Syntax and Lexical Semantics},
  author = {Hershcovich, Daniel and Schneider, Nathan and Dvir, Dotan and Prange, Jakob and de Lhoneux, Miryam and Abend, Omri},
  booktitle = {Proceedings of the 28th International Conference on Computational Linguistics},
  month = dec,
  year = {2020},
  address = {Barcelona, Spain (Online)},
  publisher = {International Committee on Computational Linguistics},
  url = {https://www.aclweb.org/anthology/2020.coling-main.264},
  doi = {10.18653/v1/2020.coling-main.264},
  pages = {2947--2966},
  abbr = {COLING}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">CL</abbr>
        
    
</div>

  <div id="delhoneux20avc" class="col-sm-9">
    
      <div class="title">What Should/Do/Can LSTMs Learn When Parsing Auxiliary Verb Constructions?</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Computational Linguistics</em>,
      
      
        2020
      
      </div>
    

    <div class="links">

    
      <a href=" 
         https://doi.org/10.1162/coli_a_00392
         " class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/naacl21_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
      
      <a href="/assets/pdf/naacl21.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p> There is a growing interest in investigating what neural NLP models learn about language. A prominent open question is the question of whether or not it is necessary to model hierarchical structure. We present a linguistic investigation of a neural parser adding insights to this question. We look at transitivity and agreement information of auxiliary verb constructions (AVCs) in comparison to finite main verbs (FMVs). This comparison is motivated by theoretical work in dependency grammar and in particular the work of TesniÃ¨re (1959), where AVCs and FMVs are both instances of a nucleus, the basic unit of syntax. An AVC is a dissociated nucleus, it consists of at least two words, and an FMV is its non-dissociated counterpart, consisting of exactly one word.We suggest that the representation of AVCs and FMVs should capture similar information. We use diagnostic classifiers to probe agreement and transitivity information in vectors learned by a transition-based neural parser in four typologically different languages. We find that the parser learns different information about AVCs and FMVs if only sequential models (BiLSTMs) are used in the architecture but similar information when a recursive layer is used. We find explanations for why this is the case by looking closely at how information is learned in the network and looking at what happens with different dependency representations of AVCs. We conclude that there may be benefits to using a recursive layer in dependency parsing and that we have not yet found the best way to integrate it in our parsers. </p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@article{delhoneux20avc,
  author = {{{de Lhoneux}}, Miryam and Stymne, Sara and Nivre, Joakim},
  title = {What Should/Do/Can LSTMs Learn When Parsing Auxiliary Verb Constructions?},
  journal = {Computational Linguistics},
  volume = {46},
  number = {4},
  pages = {1-22},
  year = {2020},
  doi = {10.1162/coli\_a\_00392},
  poster = {naacl21_poster.pdf},
  slides = {naacl21.pdf},
  abbr = {CL},
  url = { 
           https://doi.org/10.1162/coli_a_00392
           },
  eprint = { 
              https://doi.org/10.1162/coli_a_00392
              }
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">NAACL</abbr>
        
    
</div>

  <div id="delhoneux19recursive" class="col-sm-9">
    
      <div class="title">Recursive Subtree Composition in LSTM-Based Dependency Parsing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Miguel Ballesteros,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>NAACL</em>,
      
      
        2019
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/N19-1159" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
      <a href="https://github.com/mdelhoneux/uuparser-composition" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
      <a href="https://vimeo.com/364704101" class="btn btn-sm z-depth-0" role="button" target="_blank">Video</a>
    
    
    
      
      <a href="/assets/pdf/naacl_19_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    
      <a href="https://twitter.com/amirieb/status/1135913233657675780" class="btn btn-sm z-depth-0" role="button" target="_blank">Live-tweet</a>
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The need for tree structure modelling on top of sequence modelling is an open issue in neural dependency parsing. We investigate the impact of adding a tree layer on top of a sequential model by recursively composing subtree representations (composition) in a transition-based parser that uses features extracted by a BiLSTM. Composition seems superfluous with such a model, suggesting that BiLSTMs capture information about subtrees. We perform model ablations to tease out the conditions under which composition helps. When ablating the backward LSTM, performance drops and composition does not recover much of the gap. When ablating the forward LSTM, performance drops less dramatically and composition recovers a substantial part of the gap, indicating that a forward LSTM and composition capture similar information. We take the backward LSTM to be related to lookahead features and the forward LSTM to the rich history-based features both crucial for transition-based parsers. To capture history-based information, composition is better than a forward LSTM on its own, but it is even better to have a forward LSTM as part of a BiLSTM. We correlate results with language properties, showing that the improved lookahead of a backward LSTM is especially important for head-final languages.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux19recursive,
  title = {Recursive Subtree Composition in {LSTM}-Based Dependency Parsing},
  author = {{de Lhoneux}, Miryam and Ballesteros, Miguel and Nivre, Joakim},
  abbr = {NAACL},
  booktitle = {NAACL},
  month = jun,
  year = {2019},
  address = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/N19-1159},
  doi = {10.18653/v1/N19-1159},
  pages = {1566--1576},
  livetweet = {https://twitter.com/amirieb/status/1135913233657675780},
  slides = {naacl_19_slides.pdf},
  video = {https://vimeo.com/364704101},
  code = {https://github.com/mdelhoneux/uuparser-composition}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">EMNLP</abbr>
        
    
</div>

  <div id="kulmizev19deep" class="col-sm-9">
    
      <div class="title">Deep Contextualized Word Embeddings in Transition-Based and Graph-Based Dependency Parsing - A Tale of Two Parsers Revisited</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Artur Kulmizev,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Johannes Gontrum,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Elena Fano,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>EMNLP-IJCNLP</em>,
      
      
        2019
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/D19-1277" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Transition-based and graph-based dependency parsers have previously been shown to have complementary strengths and weaknesses: transition-based parsers exploit rich structural features but suffer from error propagation, while graph-based parsers benefit from global optimization but have restricted feature scope. In this paper, we show that, even though some details of the picture have changed after the switch to neural networks and continuous representations, the basic trade-off between rich features and global optimization remains essentially the same. Moreover, we show that deep contextualized word embeddings, which allow parsers to pack information about global sentence structure into local feature representations, benefit transition-based parsers more than graph-based parsers, making the two approaches virtually equivalent in terms of both accuracy and error profile. We argue that the reason is that these representations help prevent search errors and thereby allow transition-based parsers to better exploit their inherent strength of making accurate local decisions. We support this explanation by an error analysis of parsing experiments on 13 languages.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{kulmizev19deep,
  title = {Deep Contextualized Word Embeddings in Transition-Based and Graph-Based Dependency Parsing - A Tale of Two Parsers Revisited},
  author = {Kulmizev, Artur and {de Lhoneux}, Miryam and Gontrum, Johannes and Fano, Elena and Nivre, Joakim},
  booktitle = {EMNLP-IJCNLP},
  month = nov,
  year = {2019},
  address = {Hong Kong, China},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/D19-1277},
  doi = {10.18653/v1/D19-1277},
  pages = {2755--2768},
  abbr = {EMNLP}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">CoNLL UD ST</abbr>
        
    
</div>

  <div id="smith2018st" class="col-sm-9">
    
      <div class="title">82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Aaron Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bernd Bohnet,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Joakim Nivre,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yan Shao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sara Stymne
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proc. of the CoNLL 2018 Shared Task</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/K18-2011" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the Uppsala system for the CoNLL 2018 Shared Task on universal dependency parsing. Our system is a pipeline consisting of three components: the first performs joint word and sentence segmentation; the second predicts part-of-speech tags and morphological features; the third predicts dependency trees from words and tags. Instead of training a single parsing model for each treebank, we trained models with multiple treebanks for one language or closely related languages, greatly reducing the number of models. On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics. Our system obtained the best scores overall for word segmentation, universal POS tagging, and morphological features.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{smith2018st,
  title = {82 Treebanks, 34 Models: Universal Dependency Parsing with Multi-Treebank Models},
  author = {Smith, Aaron and Bohnet, Bernd and {de Lhoneux}, Miryam and Nivre, Joakim and Shao, Yan and Stymne, Sara},
  booktitle = {Proc. of the {C}o{NLL} 2018 Shared Task},
  month = oct,
  abbr = {CoNLL UD ST},
  year = {2018},
  address = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/K18-2011},
  doi = {10.18653/v1/K18-2011},
  pages = {113--123}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">EMNLP</abbr>
        
    
</div>

  <div id="delhoneux18parameter" class="col-sm-9">
    
      <div class="title">Parameter sharing between dependency parsers for
                     related languages</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Johannes Bjerva,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Isabelle Augenstein,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Anders SÃ¸gaard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>EMNLP
                     </em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
      <a href="http://aclweb.org/anthology/D18-1543" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/emnlp_parameter_sharing" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux18parameter,
  author = {{de Lhoneux}, Miryam and Bjerva, Johannes and Augenstein, Isabelle and S{\o}gaard, Anders},
  booktitle = {EMNLP
                       },
  pages = {4992--4997},
  publisher = {Association for Computational Linguistics},
  title = {Parameter sharing between dependency parsers for
                       related languages},
  year = {2018},
  poster = {emnlp_parameter_sharing},
  url = {http://aclweb.org/anthology/D18-1543},
  abbr = {EMNLP}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">EMNLP</abbr>
        
    
</div>

  <div id="smith18investigation" class="col-sm-9">
    
      <div class="title">An Investigation of the Interactions Between Pre-Trained Word Embeddings, Character Models and POS Tags in Dependency Parsing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Aaron Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>EMNLP</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/D18-1291" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We provide a comprehensive analysis of the interactions between pre-trained word embeddings, character models and POS tags in a transition-based dependency parser. While previous studies have shown POS information to be less important in the presence of character models, we show that in fact there are complex interactions between all three techniques. In isolation each produces large improvements over a baseline system using randomly initialised word embeddings only, but combining them quickly leads to diminishing returns. We categorise words by frequency, POS tag and language in order to systematically investigate how each of the techniques affects parsing quality. For many word categories, applying any two of the three techniques is almost as good as the full combined system. Character models tend to be more important for low-frequency open-class words, especially in morphologically rich languages, while POS tags can help disambiguate high-frequency function words. We also show that large character embedding sizes help even for languages with small character sets, especially in morphologically rich languages.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{smith18investigation,
  title = {An Investigation of the Interactions Between Pre-Trained Word Embeddings, Character Models and {POS} Tags in Dependency Parsing},
  author = {Smith, Aaron and {de Lhoneux}, Miryam and Stymne, Sara and Nivre, Joakim},
  booktitle = {EMNLP},
  month = oct,
  year = {2018},
  address = {Brussels, Belgium},
  publisher = {Association for Computational Linguistics},
  abbr = {EMNLP},
  url = {https://www.aclweb.org/anthology/D18-1291},
  doi = {10.18653/v1/D18-1291},
  pages = {2711--2720}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">Blackbox NLP</abbr>
        
    
</div>

  <div id="sogaard18nightmare" class="col-sm-9">
    
      <div class="title">Nightmare at test time: How punctuation prevents parsers from generalizing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Anders SÃ¸gaard,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Isabelle Augenstein
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proc. of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/W18-5404" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Punctuation is a strong indicator of syntactic structure, and parsers trained on text with punctuation often rely heavily on this signal. Punctuation is a diversion, however, since human language processing does not rely on punctuation to the same extent, and in informal texts, we therefore often leave out punctuation. We also use punctuation ungrammatically for emphatic or creative purposes, or simply by mistake. We show that (a) dependency parsers are sensitive to <i>both</i> absence of punctuation and to alternative uses; (b) neural parsers tend to be more sensitive than vintage parsers; (c) training neural parsers <i>without</i> punctuation outperforms all out-of-the-box parsers across all scenarios where punctuation departs from standard punctuation. Our main experiments are on synthetically corrupted data to study the effect of punctuation in isolation and avoid potential confounds, but we also show effects on out-of-domain data.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{sogaard18nightmare,
  title = {Nightmare at test time: How punctuation prevents parsers from generalizing},
  author = {S{\o}gaard, Anders and {de Lhoneux}, Miryam and Augenstein, Isabelle},
  booktitle = {Proc. of the 2018 {EMNLP} Workshop {B}lackbox{NLP}: Analyzing and Interpreting Neural Networks for {NLP}},
  month = nov,
  year = {2018},
  address = {Brussels, Belgium},
  abbr = {Blackbox NLP},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/W18-5404},
  doi = {10.18653/v1/W18-5404},
  pages = {25--29}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">ACL</abbr>
        
    
</div>

  <div id="stymne18parser" class="col-sm-9">
    
      <div class="title">Parser Training with Heterogeneous Treebanks</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Aaron Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>ACL</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/P18-2098" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>How to make the most of multiple heterogeneous treebanks when training a monolingual dependency parser is an open question. We start by investigating previously suggested, but little evaluated, strategies for exploiting multiple treebanks based on concatenating training sets, with or without fine-tuning. We go on to propose a new method based on treebank embeddings. We perform experiments for several languages and show that in many cases fine-tuning and treebank embeddings lead to substantial improvements over single treebanks or concatenation, with average gains of 2.0â€“3.5 LAS points. We argue that treebank embeddings should be preferred due to their conceptual simplicity, flexibility and extensibility.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{stymne18parser,
  title = {Parser Training with Heterogeneous Treebanks},
  author = {Stymne, Sara and {de Lhoneux}, Miryam and Smith, Aaron and Nivre, Joakim},
  booktitle = {ACL},
  month = jul,
  year = {2018},
  address = {Melbourne, Australia},
  abbr = {ACL},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/P18-2098},
  doi = {10.18653/v1/P18-2098},
  pages = {619--625}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">TLT</abbr>
        
    
</div>

  <div id="delhoneux17old" class="col-sm-9">
    
      <div class="title">Old School vs. New School: Comparing Transition-Based
                     Parsers with and without Neural Network Enhancement.</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>TLT </em>,
      
      
        2017
      
      </div>
    

    <div class="links">

    
      <a href="http://ceur-ws.org/Vol-1779/08delhoneux.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/TLT15_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux17old,
  abbr = {TLT},
  author = {{de Lhoneux}, Miryam and Stymne, Sara and Nivre, Joakim},
  booktitle = {TLT },
  title = {{Old School vs. New School: Comparing Transition-Based
                       Parsers with and without Neural Network Enhancement.}},
  url = {http://ceur-ws.org/Vol-1779/08delhoneux.pdf},
  year = {2017},
  slides = {TLT15_slides.pdf},
  pages = {99--110}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">CoNLL UD ST</abbr>
        
    
</div>

  <div id="delhoneux17raw" class="col-sm-9">
    
      <div class="title">From Raw Text to Universal Dependencies - Look, No Tags!</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yan Shao,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ali Basirat,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Eliyahu Kiperwasser,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Yoav Goldberg,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proc. of the CoNLL 2017 Shared Task</em>,
      
      
        2017
      
      </div>
    

    <div class="links">

    
      <a href="https://github.com/UppsalaNLP/uuparser" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/uu_conll17.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present the Uppsala submission to the CoNLL 2017 shared task on parsing from raw text to universal dependencies. Our system is a simple pipeline consisting of two components. The first performs joint word and sentence segmentation on raw text; the second predicts dependency trees from raw words. The parser bypasses the need for part-of-speech tagging, but uses word embeddings based on universal tag distributions. We achieved a macro-averaged LAS F1 of 65.11 in the official test run, which improved to 70.49 after bug fixes. We obtained the 2nd best result for sentence segmentation with a score of 89.03.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux17raw,
  title = {From Raw Text to Universal Dependencies - Look, No Tags!},
  author = {{de Lhoneux}, Miryam and Shao, Yan and Basirat, Ali and Kiperwasser, Eliyahu and Stymne, Sara and Goldberg, Yoav and Nivre, Joakim},
  booktitle = {Proc. of the {C}o{NLL} 2017 Shared Task},
  abbr = {CoNLL UD ST},
  poster = {uu_conll17.pdf},
  month = aug,
  year = {2017},
  address = {Vancouver, Canada},
  publisher = {Association for Computational Linguistics},
  url = {https://github.com/UppsalaNLP/uuparser},
  doi = {10.18653/v1/K17-3022},
  pages = {207--217}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
        
            <abbr class="badge">IWPT</abbr>
        
    
</div>

  <div id="delhoneux17arc" class="col-sm-9">
    
      <div class="title">Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Sara Stymne,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>IWPT</em>,
      
      
        2017
      
      </div>
    

    <div class="links">

    
      <a href="https://www.aclweb.org/anthology/W17-6314" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
      <a href="https://github.com/UppsalaNLP/uuparser" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
      
      <a href="/assets/pdf/IWPT2017_slides.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Slides</a>
      
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In this paper, we extend the arc-hybrid system for transition-based parsing with a swap transition that enables reordering of the words and construction of non-projective trees. Although this extension breaks the arc-decomposability of the transition system, we show how the existing dynamic oracle for this system can be modified and combined with a static oracle only for the swap transition. Experiments on 5 languages show that the new system gives competitive accuracy and is significantly better than a system trained with a purely static oracle.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux17arc,
  abbr = {IWPT},
  title = {Arc-Hybrid Non-Projective Dependency Parsing with a Static-Dynamic Oracle},
  author = {{de Lhoneux}, Miryam and Stymne, Sara and Nivre, Joakim},
  booktitle = {IWPT},
  month = sep,
  year = {2017},
  address = {Pisa, Italy},
  publisher = {Association for Computational Linguistics},
  url = {https://www.aclweb.org/anthology/W17-6314},
  code = {https://github.com/UppsalaNLP/uuparser},
  pages = {99--104},
  slides = {IWPT2017_slides.pdf}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux16should" class="col-sm-9">
    
      <div class="title">Should Have, Would Have, Could Have. Investigating
                     Verb Group Representations for Parsing with Universal
                     Dependencies.</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>Proc. of the Workshop on Multilingual and
                     Cross-lingual Methods in NLP</em>,
      
      
        2016
      
      </div>
    

    <div class="links">

    
    
    
    
    
    
    
    
    
    
      
      <a href="/assets/pdf/MLCL16_poster.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">Poster</a>
      
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux16should,
  author = {{de Lhoneux}, Miryam and Nivre, Joakim},
  booktitle = {Proc. of the Workshop on Multilingual and
                       Cross-lingual Methods in NLP},
  pages = {10--19},
  publisher = {Association for Computational Linguistics},
  title = {{Should Have, Would Have, Could Have. Investigating
                       Verb Group Representations for Parsing with Universal
                       Dependencies.}},
  year = {2016},
  poster = {MLCL16_poster.pdf},
  doi = {10.18653/v1/W16-1202}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

</div>

<p><br /></p>
<div class="publications">
<h4 class="category"> Book chapters</h4>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux19investigating" class="col-sm-9">
    
      <div class="title">Investigating the effect of automatic MWE recognition on CCG parsing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Omri Abend,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Mark Steedman
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">

    
      <a href="http://langsci-press.org/catalog/book/202" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@incollection{delhoneux19investigating,
  title = {{Investigating the effect of automatic MWE recognition on CCG parsing}},
  author = {{de Lhoneux}, Miryam and Abend, Omri and Steedman, Mark},
  editor = {Parmentier, Yannick and Waszczuk, Jakub},
  booktitle = {Representation and parsing of multiword expressions},
  publisher = {Language Science Press},
  address = {Berlin},
  pages = {183-215},
  year = {2019},
  chapter = {7},
  url = {http://langsci-press.org/catalog/book/202}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

</div>

<div class="publications">
<h4 class="category">Theses</h4>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux19" class="col-sm-9">
    
      <div class="title">Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Miryam de Lhoneux</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">

    
      <a href="http://www.diva-portal.org/smash/get/diva2:1357373/FULLTEXT01.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@phdthesis{delhoneux19,
  title = {{Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages}},
  author = {{de Lhoneux}, Miryam},
  school = {Uppsala University},
  year = {2019},
  url = {http://www.diva-portal.org/smash/get/diva2:1357373/FULLTEXT01.pdf}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux14" class="col-sm-9">
    
      <div class="title">CCG Parsing and Multiword Expressions</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Miryam de Lhoneux</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2014
      
      </div>
    

    <div class="links">

    
      <a href="https://arxiv.org/pdf/1505.04420.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">URL</a>
    
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This thesis presents a study about the integration of information about Multiword Expressions (MWEs) into parsing with Combinatory Categorial Grammar (CCG). We build on previous work which has shown the benefit of adding information about MWEs to syntactic parsing by implementing a similar pipeline with CCG parsing. More specifically, we collapse MWEs to one token in training and test data in CCGbank, a corpus which contains sentences annotated with CCG derivations. Our collapsing algorithm however can only deal with MWEs when they form a constituent in the data which is one of the limitations of our approach. 
                                We study the effect of collapsing training and test data. A parsing effect can be obtained if collapsed data help the parser in its decisions and a training effect can be obtained if training on the collapsed data improves results. We also collapse the gold standard and show that our model significantly outperforms the baseline model on our gold standard, which indicates that there is a training effect. We show that the baseline model performs significantly better on our gold standard when the data are collapsed before parsing than when the data are collapsed after parsing which indicates that there is a parsing effect. We show that these results can lead to improved performance on the non-collapsed standard benchmark although we fail to show that it does so significantly. 
                                We conclude that despite the limited settings, there are noticeable improvements from using MWEs in parsing. We discuss ways in which the incorporation of MWEs into parsing can be improved and hypothesize that this will lead to more substantial results.
                                We finally show that turning the MWE recognition part of the pipeline into an experimental part is a useful thing to do as we obtain different results with different recognizers.</p>
    </div>
    
    
    <div class="bibtex hidden">
    <p>@mastersthesis{delhoneux14,
  title = {{CCG Parsing and Multiword Expressions}},
  author = {{de Lhoneux}, Miryam},
  school = {The University of Edinburgh},
  year = {2014},
  month = aug,
  url = {https://arxiv.org/pdf/1505.04420.pdf}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux13" class="col-sm-9">
    
      <div class="title">Towards a Systematic Contrastive Constructional Approach to the Resultative Construction: An Exploratory Study on English and French</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Miryam de Lhoneux</em>
            
          
        
      </div>

      <div class="periodical">
      
      
        2013
      
      </div>
    

    <div class="links">

    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@mastersthesis{delhoneux13,
  author = {{de Lhoneux}, Miryam},
  title = {{Towards a Systematic Contrastive Constructional Approach to the Resultative Construction: An Exploratory Study on English and French}},
  school = {{UniversitÃ© catholique de Louvain}},
  year = {2013},
  month = may
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

</div>

<div class="publications">
<h4 class="category">Non-archival stuff</h4>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="nivre18universal" class="col-sm-9">
    
      <div class="title">Universal Dependency Parsing at Uppsala University</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Joakim Nivre,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Aaron Smith,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Sara Stymne
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>SLTC</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{nivre18universal,
  title = {Universal Dependency Parsing at Uppsala University},
  author = {Nivre, Joakim and {de Lhoneux}, Miryam and Smith, Aaron and Stymne, Sara},
  booktitle = {SLTC},
  pages = {65},
  year = {2018}
}
</p>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux18sltc" class="col-sm-9">
    
      <div class="title">Parameter Sharing in Multilingual Dependency Parsing</div>
      <div class="author">
        
          
          
          
          
          
          
            
              <em>Miryam de Lhoneux</em>
            
          
        
      </div>

      <div class="periodical">
      
        In <em>SLTC</em>,
      
      
        2018
      
      </div>
    

    <div class="links">

    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux18sltc,
  title = {Parameter Sharing in Multilingual Dependency Parsing},
  author = {{de Lhoneux}, Miryam},
  booktitle = {SLTC},
  pages = {31},
  year = {2018}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"><li><div class="row">
<div class="col-sm-2 abbr">
    
</div>

  <div id="delhoneux16ud" class="col-sm-9">
    
      <div class="title">UD treebank sampling for comparative parser evaluation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Miryam de Lhoneux</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Joakim Nivre
                
              
            
          
        
      </div>

      <div class="periodical">
      
        In <em>SLTC</em>,
      
      
        2016
      
      </div>
    

    <div class="links">

    
    
    
    
    
    
    
    
    
    
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">bibtex</a>
    
    

    </div>

    <!-- Hidden abstract block -->
    
    
    <div class="bibtex hidden">
    <p>@inproceedings{delhoneux16ud,
  title = {{UD treebank sampling for comparative parser evaluation}},
  author = {{de Lhoneux}, Miryam and Nivre, Joakim},
  booktitle = {SLTC},
  year = {2016}
}
</p>
    </div>
    
  </div>
</div>
</li></ol>

</div>

<p><br /></p>
<div class="talks">
<span id="talks"></span>
<h1 class="category">Talks</h1>

      <ul>
		  <li> Low-resource NLP: Lessons from Dependency Parsing. <a href="https://sigtyp.io/ws2021.html">Sigtyp 2021</a>, 10 June 2021. [<a href="https://www.youtube.com/watch?v=HrzrlhMnde0">video</a>|<a href="/assets/pdf/sigtyp21.pdf">slides</a>]
		  <li> Parsing Typologically Diverse Languages. Aix Marseille University, 26 Nov 2020.
		  <li> Parsing Typologically Diverse Languages. Workshop on <a href="https://tlt2020.phil.hhu.de/">Treebanks ang Linguistic Theories</a> (TLT), 27 October 2020. [<a href="https://t.co/937VFXcpPP">video</a>|<a href="/assets/pdf/tlt_2020_slides.pdf">slides</a>]
          <li> Do we need recursive subtree composition in dependency parsing? Invited talk at the Workshop on Data-driven Approaches to Parsing and Semantic Composition, TÃ¼bingen 10 December 2019. [<a href="/assets/pdf/tubingen1219.pdf">slides</a>]
</li></li></li></li></ul></div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Miryam  de Lhoneux.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    
    Last updated: July 02, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
